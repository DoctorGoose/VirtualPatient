{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Time points\n",
    "t_points = np.linspace(0, 10, 100)\n",
    "\n",
    "# Synthetic data for two states\n",
    "data_state_1 = np.sin(t_points) + np.random.normal(0, 0.1, len(t_points))\n",
    "data_state_2 = np.cos(t_points) + np.random.normal(0, 0.1, len(t_points))\n",
    "\n",
    "# Assemble into a DataFrame\n",
    "synthetic_data = pd.DataFrame({'Time': t_points, 'State1': data_state_1, 'State2': data_state_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_model(t, params):\n",
    "    \"\"\"\n",
    "    A toy model function.\n",
    "    :param t: Time array\n",
    "    :param params: Dictionary of parameters\n",
    "    :return: Model states as np.array\n",
    "    \"\"\"\n",
    "    # Unpack parameters\n",
    "    p1, p2, p3 = params['p1'], params['p2'], params['p3']\n",
    "    \n",
    "    # Toy model equations (simplified)\n",
    "    state1 = np.sin(p1 * t)\n",
    "    state2 = np.cos(p2 * t)\n",
    "    state3 = np.sin(p3 * t) + np.cos((p1+p2) * t)\n",
    "    \n",
    "    return np.array([state1, state2, state3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import Sobol\n",
    "import numpy as np\n",
    "\n",
    "# Number of parameters\n",
    "dim = 3\n",
    "# Recommended number of points for Sobol sequence\n",
    "n_samples = 256\n",
    "\n",
    "# Generate Sobol samples in [0, 1] range\n",
    "sobol_gen = Sobol(d=dim, scramble=True)\n",
    "samples = sobol_gen.random_base2(m=int(np.log2(n_samples)))\n",
    "\n",
    "# Convert samples to log space if parameters are distributed log-uniformly\n",
    "# Assuming parameter ranges are known\n",
    "param_ranges = [(0.1, 10), (0.1, 10), (0.1, 10)]  # Example ranges for each parameter\n",
    "log_samples = np.zeros_like(samples)\n",
    "for i in range(dim):\n",
    "    min_log, max_log = np.log10(param_ranges[i])\n",
    "    log_samples[:, i] = np.power(10, min_log + (max_log - min_log) * samples[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sse(parameter_set, synthetic_data, time_points):\n",
    "    \"\"\"\n",
    "    Compute the SSE between the model output and synthetic data for all states over time.\n",
    "    \n",
    "    :param parameter_set: Array-like, the set of parameters for the model.\n",
    "    :param synthetic_data: DataFrame, the synthetic data against which to compare the model output.\n",
    "    :param time_points: Array-like, the time points at which to evaluate the model and synthetic data.\n",
    "    :return: The sum of squared errors for each state over time.\n",
    "    \"\"\"\n",
    "    # Assume parameter_set is a dictionary or structure from which you can extract parameters\n",
    "    p1, p2, p3 = parameter_set\n",
    "    \n",
    "    # Run the model with the given parameters\n",
    "    model_output = toy_model(time_points, {'p1': p1, 'p2': p2, 'p3': p3})\n",
    "    \n",
    "    # Initialize SSE\n",
    "    sse = 0\n",
    "    \n",
    "    # For each state that we have synthetic data for, calculate SSE\n",
    "    for state in ['State1', 'State2']:  # Adjust based on your actual states with synthetic data\n",
    "        # Extract the corresponding model output for this state\n",
    "        model_state_output = model_output[state_to_index(state)]  # Define state_to_index mapping\n",
    "        \n",
    "        # Extract the corresponding synthetic data for this state\n",
    "        synthetic_state_data = synthetic_data[state].values\n",
    "        \n",
    "        # Calculate SSE for this state\n",
    "        state_sse = np.sum((model_state_output - synthetic_state_data) ** 2)\n",
    "        \n",
    "        # Add to total SSE\n",
    "        sse += state_sse\n",
    "    \n",
    "    return sse\n",
    "\n",
    "def state_to_index(state_name):\n",
    "    \"\"\"\n",
    "    Helper function to map state name to index in the model_output array.\n",
    "    Adjust this mapping based on your actual model output structure.\n",
    "    \"\"\"\n",
    "    mapping = {'State1': 0, 'State2': 1}  # Example mapping, adjust as needed\n",
    "    return mapping[state_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from SALib.util import read_param_file\n",
    "\n",
    "# Define the model inputs for SALib\n",
    "problem = {\n",
    "    'num_vars': 3,\n",
    "    'names': ['p1', 'p2', 'p3'],\n",
    "    'bounds': [[0.1, 10] for _ in range(3)]  # Corresponding to log-scaled bounds\n",
    "}\n",
    "\n",
    "# Perform Sobol sensitivity analysis using the model outputs\n",
    "Si = sobol.analyze(problem, model_outputs, print_to_console=True)\n",
    "\n",
    "# Si now contains Sobol sensitivity indices, which can be used to inform the exploration and optimization strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPyOpt\n",
    "\n",
    "# Define bounds based on sensitivity analysis insights, focusing on sensitive parameters\n",
    "bounds = [{'name': 'p1', 'type': 'continuous', 'domain': (0.1, 10)},\n",
    "          {'name': 'p2', 'type': 'continuous', 'domain': (0.1, 10)},\n",
    "          {'name': 'p3', 'type': 'continuous', 'domain': (0.1, 10)}]\n",
    "\n",
    "# Define the objective function for Bayesian optimization\n",
    "def objective_function(params):\n",
    "    \"\"\"\n",
    "    Objective function to be minimized, e.g., model SSE or another performance metric.\n",
    "    \"\"\"\n",
    "    # Placeholder for actual objective calculation\n",
    "    # Ensure this is aligned with your model's evaluation mechanism\n",
    "    return evaluate_model(params)\n",
    "\n",
    "# Initialize and run Bayesian optimization\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(f=objective_function, domain=bounds)\n",
    "optimizer.run_optimization(max_iter=50)  # Adjust the iteration count as needed\n",
    "\n",
    "# The optimizer object now contains the optimized parameters and minimal objective value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
