{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ASA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\AppData\\Local\\Temp\\ipykernel_33460\\1233056598.py:148: RuntimeWarning: invalid value encountered in log10\n",
      "  log_lb, log_ub = np.log10(lower_bounds), np.log10(upper_bounds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bounds must be finite numbers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 180\u001b[0m\n\u001b[0;32m    177\u001b[0m initial_solution \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbounds), dim)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Run benchmarks\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m results, histories \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_solution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evaluations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBenchmark Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 147\u001b[0m, in \u001b[0;36mbenchmark_methods\u001b[1;34m(tracker, methods, bounds, dim, initial_solution, max_evaluations, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    146\u001b[0m tracker\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 147\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_solution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m: method,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Cost\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime (s)\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    152\u001b[0m })\n\u001b[0;32m    153\u001b[0m histories[method] \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mhistory\n",
      "Cell \u001b[1;32mIn[21], line 133\u001b[0m, in \u001b[0;36mrun_algorithm\u001b[1;34m(tracker, method, bounds, dim, initial_solution, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_algorithm\u001b[39m(tracker, method, bounds, dim, initial_solution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mASA\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_asa_with_tracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_solution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPSO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m run_pso_with_tracker(tracker, bounds, dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[21], line 57\u001b[0m, in \u001b[0;36mrun_asa_with_tracker\u001b[1;34m(tracker, bounds, initial_solution, initial_temp, cooling_rate, maxiter)\u001b[0m\n\u001b[0;32m     54\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# 3) Call the new ASA function\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mASA\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracked_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_solution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_temp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_temp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcooling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcooling_rate\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     67\u001b[0m total_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[20], line 151\u001b[0m, in \u001b[0;36mASA\u001b[1;34m(objective_function, x0, bounds, maxiter, initial_temp, cooling_rate, neighborhood_function, init_function, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m log_lb, log_ub \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(lower_bounds), np\u001b[38;5;241m.\u001b[39mlog10(upper_bounds)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Generate initial solution on a log scale, then exponentiate back\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m initial_solution \u001b[38;5;241m=\u001b[39m \u001b[43minit_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_lb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_ub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Run ASA optimization\u001b[39;00m\n\u001b[0;32m    154\u001b[0m best_solution, best_cost \u001b[38;5;241m=\u001b[39m simulated_annealing(\n\u001b[0;32m    155\u001b[0m     objective_function, \n\u001b[0;32m    156\u001b[0m     initial_solution, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    168\u001b[0m )\n",
      "Cell \u001b[1;32mIn[20], line 51\u001b[0m, in \u001b[0;36mvfsa_generinitpoint\u001b[1;34m(dim, log_lb, log_ub, rng)\u001b[0m\n\u001b[0;32m     48\u001b[0m     rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng()\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(log_lb)) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(log_ub))):\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBounds must be finite numbers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(log_lb \u001b[38;5;241m>\u001b[39m log_ub):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLower bounds must be <= upper bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Bounds must be finite numbers"
     ]
    }
   ],
   "source": [
    "#  Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.optimize import minimize, OptimizeResult  \n",
    "from collections import deque   \n",
    "\n",
    "# Model\n",
    "def rastrigin(x):\n",
    "    \"\"\"Rastrigin function for optimization benchmark.\"\"\"\n",
    "    A = 10\n",
    "    return A * len(x) + sum([(xi ** 2 - A * np.cos(2 * np.pi * xi)) for xi in x])\n",
    "\n",
    "#  Evaluation Tracker \n",
    "class EvaluationTracker:\n",
    "    def __init__(self, objective_function, max_evaluations):\n",
    "        self.objective_function = objective_function\n",
    "        self.max_evaluations = max_evaluations\n",
    "        self.evaluation_count = 0\n",
    "        self.history = []\n",
    "\n",
    "    def evaluate(self, position):\n",
    "        \n",
    "        cost = self.objective_function(position)\n",
    "        self.history.append({\n",
    "            \"step\": self.evaluation_count,\n",
    "            \"position\": position.copy(),\n",
    "            \"cost\": cost,\n",
    "        })\n",
    "        self.evaluation_count += 1\n",
    "        return cost\n",
    "\n",
    "    def reset(self):\n",
    "        self.evaluation_count = 0\n",
    "        self.history = []\n",
    "\n",
    "def run_asa_with_tracker(tracker, bounds, initial_solution, \n",
    "                         initial_temp=1.0, cooling_rate=0.95, \n",
    "                         maxiter=None):\n",
    "    \"\"\"\n",
    "    Wraps the new ASA method so that it uses the tracker to count evaluations.\n",
    "    \"\"\"\n",
    "    if maxiter is None:\n",
    "        # We'll use tracker.max_evaluations as the ASA max iterations\n",
    "        maxiter = tracker.max_evaluations\n",
    "    \n",
    "    # 1) Wrap the tracker's evaluate method so ASA calls it instead of the raw objective.\n",
    "    def tracked_objective(x):\n",
    "        return tracker.evaluate(x)\n",
    "\n",
    "    # 2) Time the ASA run\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 3) Call the new ASA function\n",
    "    result = ASA(\n",
    "        objective_function=tracked_objective,\n",
    "        x0=initial_solution,\n",
    "        bounds=bounds,\n",
    "        maxiter=maxiter,\n",
    "        initial_temp=initial_temp,\n",
    "        cooling_rate=cooling_rate\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # The result is a scipy OptimizeResult, so extract best solution & cost\n",
    "    best_solution = result.x\n",
    "    best_cost = result.fun\n",
    "    \n",
    "    # Return in the same format as your other methods:\n",
    "    return best_solution, best_cost, total_time\n",
    "\n",
    "#  PSO \n",
    "class Particle:\n",
    "    def __init__(self, bounds, dim):\n",
    "        self.position = np.random.uniform(bounds[:, 0], bounds[:, 1], dim)\n",
    "        self.velocity = np.random.uniform(-1, 1, dim)\n",
    "        self.best_position = np.copy(self.position)\n",
    "        self.best_cost = float('inf')\n",
    "\n",
    "    def update_velocity(self, global_best_position, inertia, cognitive, social, bounds):\n",
    "        r1, r2 = np.random.rand(), np.random.rand()\n",
    "        cognitive_component = cognitive * r1 * (self.best_position - self.position)\n",
    "        social_component = social * r2 * (global_best_position - self.position)\n",
    "        self.velocity = inertia * self.velocity + cognitive_component + social_component\n",
    "        self.velocity = np.clip(self.velocity, -np.abs(bounds[:, 1] - bounds[:, 0]), np.abs(bounds[:, 1] - bounds[:, 0]))\n",
    "\n",
    "    def update_position(self, bounds):\n",
    "        self.position += self.velocity\n",
    "        self.position = np.clip(self.position, bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "def run_pso_with_tracker(tracker, bounds, dim, swarm_size=50, inertia=0.5, cognitive=1.5, social=1.5):\n",
    "    bounds = np.array(bounds)\n",
    "    particles = [Particle(bounds, dim) for _ in range(swarm_size)]\n",
    "    global_best_position = None\n",
    "    global_best_cost = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "    while tracker.evaluation_count < tracker.max_evaluations:\n",
    "        for particle in particles:\n",
    "            cost = tracker.evaluate(particle.position)\n",
    "            if cost < particle.best_cost:\n",
    "                particle.best_cost = cost\n",
    "                particle.best_position = np.copy(particle.position)\n",
    "            if cost < global_best_cost:\n",
    "                global_best_cost = cost\n",
    "                global_best_position = np.copy(particle.position)\n",
    "\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(global_best_position, inertia, cognitive, social, bounds)\n",
    "            particle.update_position(bounds)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    return global_best_position, global_best_cost, total_time\n",
    "\n",
    "# Differential Evolution \n",
    "def run_de_with_tracker(tracker, bounds):\n",
    "    def objective_wrapper(x):\n",
    "        return tracker.evaluate(x)\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = differential_evolution(objective_wrapper, bounds, popsize=int(10), maxiter=int(tracker.max_evaluations/10), strategy='best1bin', disp=False)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    return result.x, result.fun, total_time\n",
    "\n",
    "#  Benchmarking\n",
    "def run_algorithm(tracker, method, bounds, dim, initial_solution=None, **kwargs):\n",
    "    if method == \"ASA\":\n",
    "        return run_asa_with_tracker(tracker, bounds, initial_solution, **kwargs)\n",
    "    elif method == \"PSO\":\n",
    "        return run_pso_with_tracker(tracker, bounds, dim, **kwargs)\n",
    "    elif method == \"DE\":\n",
    "        return run_de_with_tracker(tracker, bounds)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "def benchmark_methods(tracker, methods, bounds, dim, initial_solution, max_evaluations, **kwargs):\n",
    "    results = []\n",
    "    histories = {}\n",
    "    for method in methods:\n",
    "        print(f\"Running {method}...\")\n",
    "        tracker.reset()\n",
    "        result = run_algorithm(tracker, method, bounds, dim, initial_solution, **kwargs)\n",
    "        results.append({\n",
    "            \"Algorithm\": method,\n",
    "            \"Best Cost\": result[1],\n",
    "            \"Time (s)\": result[2]\n",
    "        })\n",
    "        histories[method] = tracker.history\n",
    "    return results, histories\n",
    "\n",
    "def visualize_paths(histories, methods):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for method in methods:\n",
    "        history = histories[method]\n",
    "        costs = [h[\"cost\"] for h in history]\n",
    "        plt.plot(range(len(costs)), costs, label=method)\n",
    "    plt.xlabel(\"Evaluation Step\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.title(\"Cost Evolution by Optimization Algorithm\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    dim = 10\n",
    "    bounds = [(-5.12, 5.12) for _ in range(dim)]\n",
    "    max_evaluations = 2500\n",
    "    methods = [\"ASA\", \"PSO\"]\n",
    "\n",
    "    tracker = EvaluationTracker(rastrigin, max_evaluations)\n",
    "    initial_solution = np.random.uniform(*zip(*bounds), dim)\n",
    "\n",
    "    # Run benchmarks\n",
    "    results, histories = benchmark_methods(tracker, methods, bounds, dim, initial_solution, max_evaluations)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"Benchmark Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    # Visualize results\n",
    "    visualize_paths(histories, methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vfsa_accprob(curr_cost, new_cost, temp_acc):\n",
    "    exponent = np.clip((new_cost - curr_cost) / temp_acc, -500, 500)\n",
    "    return 1 / (1 + np.exp(exponent))\n",
    "\n",
    "def vfsa_gen_step(dim, log_lb, log_ub, temp_gen, rng=None):\n",
    "    if rng is None: \n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    uni = rng.random(dim)\n",
    "    base = 1 + 1 / (temp_gen + 1e-10)  # Small value added to avoid division by zero\n",
    "    exponent = 2 * uni - 1\n",
    "    rnd = np.sign(uni - 0.5) * temp_gen * (base**np.abs(exponent) - 1)\n",
    "    return (log_ub - log_lb) * rnd\n",
    "\n",
    "def vfsa_gen_params(curr_params, dim, log_lb, log_ub, temp_gen, rng=None):\n",
    "    if rng is None: \n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    log_params = np.log10(curr_params)\n",
    "    flag1 = True\n",
    "\n",
    "    while flag1:\n",
    "        # Generate a log step\n",
    "        log_step = vfsa_gen_step(dim, log_lb, log_ub, temp_gen, rng)\n",
    "        new_log_params = log_params + log_step\n",
    "\n",
    "        # Check if all new parameters are within bounds\n",
    "        if np.all(new_log_params >= log_lb) and np.all(new_log_params <= log_ub):\n",
    "            par = 10 ** new_log_params\n",
    "            flag1 = False\n",
    "        else:\n",
    "            # If any parameter is out of bounds, handle them individually\n",
    "            for i in range(dim):\n",
    "                if new_log_params[i] < log_lb[i] or new_log_params[i] > log_ub[i]:\n",
    "                    flag2 = True\n",
    "                    while flag2:\n",
    "                        log_step = vfsa_gen_step(dim, log_lb, log_ub, temp_gen, rng)\n",
    "                        new_log_params[i] = log_params[i] + log_step[i]\n",
    "                        if log_lb[i] <= new_log_params[i] <= log_ub[i]:\n",
    "                            flag2 = False\n",
    "            par = 10 ** new_log_params\n",
    "            flag1 = False\n",
    "\n",
    "    return par\n",
    "        \n",
    "def vfsa_generinitpoint(dim, log_lb, log_ub, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    if not (np.all(np.isfinite(log_lb)) and np.all(np.isfinite(log_ub))):\n",
    "        raise ValueError(\"Bounds must be finite numbers\")\n",
    "    if np.any(log_lb > log_ub):\n",
    "        raise ValueError(\"Lower bounds must be <= upper bounds\")\n",
    "    \n",
    "    flag = True\n",
    "    while flag:\n",
    "        uni = rng.random(dim)\n",
    "        log_initpoints = log_lb + (log_ub - log_lb) * uni\n",
    "        if np.all(log_initpoints >= log_lb) and np.all(log_initpoints <= log_ub):\n",
    "            flag = False\n",
    "    return 10 ** log_initpoints\n",
    "\n",
    "def vfsa_reannealing(best_cost, best_params, curr_cost, dim, x0, tmax, tscat, data, c, temp_gen, temp0_gen, objective_function):\n",
    "    # Provided for completeness but not strictly used in the minimal ASA example\n",
    "    log_orig_best_params = np.log10(best_params)\n",
    "    log_par_delta = log_orig_best_params + 0.01 * log_orig_best_params\n",
    "    par_delta = 10 ** log_par_delta\n",
    "    \n",
    "    cost_delta = np.array([\n",
    "        objective_function(par_delta if i == j else best_params)\n",
    "        for j in range(dim)\n",
    "    ])\n",
    "    \n",
    "    par_diff = np.clip(par_delta - best_params, 1e-10, None)\n",
    "    s = np.abs((cost_delta - best_cost) / par_diff) * (best_params / best_cost)\n",
    "    smax = np.max(s)\n",
    "    \n",
    "    temp_gen = np.clip(temp_gen * (smax / np.clip(s, 1e-10, None)), 1e-10, None)\n",
    "    \n",
    "    k_gen = (-1/c * np.log(np.clip(temp_gen / temp0_gen, 1e-10, None))) ** dim\n",
    "    k_gen = np.clip(k_gen, 0, None)\n",
    "    \n",
    "    temp0_acc = curr_cost\n",
    "    temp_acc = best_cost\n",
    "    k_acc = (-1/c * np.log(np.clip(temp_acc / temp0_acc, 1e-10, None))) ** dim\n",
    "    \n",
    "    return temp_gen, k_gen, temp0_acc, temp_acc, k_acc\n",
    "\n",
    "def vfsa_temp(temp_gen0, c, k_gen, dim, min_temp=1e-10):\n",
    "    exponent = -c * np.power(k_gen, 1/dim)\n",
    "    temp = temp_gen0 * np.exp(exponent)\n",
    "    return np.clip(temp, min_temp, None)\n",
    "\n",
    "def simulated_annealing(objective_function, initial_solution, lower_bounds, upper_bounds, \n",
    "                        initial_temperature, cooling_rate, max_iterations, neighborhood_function, \n",
    "                        log_lb, log_ub, temp_gen, \n",
    "                        M=10, eps=0.0, min_temp=1e-10, verbose=False):\n",
    "    \n",
    "    current_solution = initial_solution\n",
    "    current_cost = objective_function(current_solution)\n",
    "    best_solution = current_solution\n",
    "    best_cost = current_cost\n",
    "    temperature = initial_temperature\n",
    "\n",
    "    reanneal_cost_vec = [best_cost]\n",
    "    diff = deque(maxlen=M)\n",
    "    best_diff = deque(maxlen=M)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Generate a new solution\n",
    "        new_solution = neighborhood_function(current_solution, len(current_solution), \n",
    "                                             log_lb, log_ub, temp_gen)\n",
    "        new_cost = objective_function(new_solution)\n",
    "        delta_cost = new_cost - current_cost\n",
    "        \n",
    "        # Acceptance\n",
    "        if delta_cost < 0 or np.random.rand() < np.exp(-delta_cost / temperature):\n",
    "            current_solution = new_solution\n",
    "            current_cost = new_cost\n",
    "            if current_cost < best_cost:\n",
    "                best_solution = current_solution\n",
    "                best_cost = current_cost\n",
    "\n",
    "            reanneal_cost_vec.append(best_cost)\n",
    "            if len(reanneal_cost_vec) > 1:\n",
    "                diff.append(abs(reanneal_cost_vec[-1] - reanneal_cost_vec[-2]))\n",
    "                best_diff.append(abs(reanneal_cost_vec[-1] - best_cost))\n",
    "\n",
    "                if (len(diff) == M \n",
    "                    and all(d <= eps for d in diff) \n",
    "                    and all(bd <= eps for bd in best_diff)):\n",
    "                    print('ASA converged, terminating at iteration', iteration)\n",
    "                    break\n",
    "        \n",
    "        temperature = max(min_temp, temperature * cooling_rate)\n",
    "        \n",
    "        if iteration % (max_iterations // 10) == 0:\n",
    "            print(f\"ASA iteration {iteration}, current cost={current_cost}, best cost={best_cost}\")\n",
    "        \n",
    "    return best_solution, best_cost\n",
    "\n",
    "def ASA(objective_function, x0, bounds, maxiter=100, initial_temp=1.0, cooling_rate=0.95, \n",
    "        neighborhood_function=vfsa_gen_params, init_function=vfsa_generinitpoint, \n",
    "        **kwargs):\n",
    "    \n",
    "    dim = len(x0)\n",
    "    lower_bounds, upper_bounds = np.array(bounds).T\n",
    "    log_lb, log_ub = np.log10(lower_bounds), np.log10(upper_bounds)\n",
    "\n",
    "    # Generate initial solution on a log scale, then exponentiate back\n",
    "    initial_solution = init_function(dim, log_lb, log_ub)\n",
    "    \n",
    "    # Run ASA optimization\n",
    "    best_solution, best_cost = simulated_annealing(\n",
    "        objective_function, \n",
    "        initial_solution, \n",
    "        lower_bounds, \n",
    "        upper_bounds,\n",
    "        initial_temp, \n",
    "        cooling_rate, \n",
    "        maxiter, \n",
    "        neighborhood_function,\n",
    "        log_lb, \n",
    "        log_ub, \n",
    "        initial_temp,  # passing `initial_temp` as `temp_gen` for simplicity\n",
    "        verbose=False,\n",
    "        **kwargs\n",
    "    )\n",
    "    print('ASA best cost:', best_cost)\n",
    "    print('ASA best solution:', best_solution)\n",
    "\n",
    "    # Optionally, do a local refinement with SciPy's minimize (L-BFGS-B)\n",
    "    minimizer_kwargs = {\n",
    "        'method': 'L-BFGS-B',\n",
    "        'bounds': bounds,\n",
    "        'options': {\n",
    "            'disp': True,\n",
    "            'maxiter': 250,\n",
    "        }\n",
    "    }\n",
    "    local_result = minimize(objective_function, x0=best_solution, **minimizer_kwargs)\n",
    "    \n",
    "    final_solution = local_result.x\n",
    "    final_cost = local_result.fun\n",
    "    nfev = local_result.nfev\n",
    "    success = local_result.success\n",
    "\n",
    "    return OptimizeResult(x=final_solution, fun=final_cost, nfev=nfev, success=success)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
